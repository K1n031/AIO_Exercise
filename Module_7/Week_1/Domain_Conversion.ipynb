{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Skip Connection Unet Architecture"
      ],
      "metadata": {
        "id": "py9CHU7hh_u9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Bb4cU7UShdUu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "class FirstFeature(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(FirstFeature, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "zterrHg1h6rB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            ConvBlock(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GuHJiTY7iCUx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
        "            nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "        self.conv_block = ConvBlock(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.conv(x)\n",
        "        x = torch.concat([x, skip], dim=1)\n",
        "        x = self.conv_block(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "QOFbrPN2iDkZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FinalOutput(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(FinalOutput, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "ehlK655iiFSS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet(nn.Module):\n",
        "    def __init__(self, n_channels=3, n_classes=3, features=[64, 128, 256, 512]):\n",
        "        super(Unet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.in_conv1 = FirstFeature(n_channels, 64)\n",
        "        self.in_conv2 = ConvBlock(64, 64)\n",
        "\n",
        "        self.enc_1 = Encoder(64, 128)\n",
        "        self.enc_2 = Encoder(128, 256)\n",
        "        self.enc_3 = Encoder(256, 512)\n",
        "        self.enc_4 = Encoder(512, 1024)\n",
        "\n",
        "        self.dec_1 = Decoder(1024, 512)\n",
        "        self.dec_2 = Decoder(512, 256)\n",
        "        self.dec_3 = Decoder(256, 128)\n",
        "        self.dec_4 = Decoder(128, 64)\n",
        "\n",
        "        self.out_conv = FinalOutput(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.in_conv1(x)\n",
        "        x1 = self.in_conv2(x)\n",
        "\n",
        "        x2 = self.enc_1(x1)\n",
        "        x3 = self.enc_2(x2)\n",
        "        x4 = self.enc_3(x3)\n",
        "        x5 = self.enc_4(x4)\n",
        "\n",
        "        x = self.dec_1(x5, x4)\n",
        "        x = self.dec_2(x, x3)\n",
        "        x = self.dec_3(x, x2)\n",
        "        x = self.dec_4(x, x1)\n",
        "\n",
        "        x = self.out_conv(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Aed6Tz6ZiGvj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Super Resolution with U-Net"
      ],
      "metadata": {
        "id": "97Bv-0H4iVdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstFeatureNoSkip(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(FirstFeatureNoSkip, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "hRl3a5aQi-z-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlockNoSkip(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlockNoSkip, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "Ql2J9Ulki_Ng"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderNoSkip(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EncoderNoSkip, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            ConvBlockNoSkip(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)"
      ],
      "metadata": {
        "id": "atVOxpZYjCOO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderNoSkip(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DecoderNoSkip, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
        "            nn.Conv2d(in_channels, out_channels * 2, 1, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * 2),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "        self.conv_block = ConvBlockNoSkip(out_channels * 2, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.conv_block(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GGmaBoaniIFD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FinalOutputNoSkip(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(FinalOutputNoSkip, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "v3FC7BGKjGoW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOW_IMG_HEIGHT = 64\n",
        "\n",
        "class SR_Unet_NoSkip(nn.Module):\n",
        "    def __init__(self, n_channels=3, n_classes=3):\n",
        "        super(SR_Unet_NoSkip, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.resize_fnc = transforms.Resize((LOW_IMG_HEIGHT * 4, LOW_IMG_HEIGHT * 4), antialias=True)\n",
        "\n",
        "        self.in_conv1 = FirstFeatureNoSkip(n_channels, 64)\n",
        "        self.in_conv2 = ConvBlockNoSkip(64, 64)\n",
        "\n",
        "        self.enc_1 = EncoderNoSkip(64, 128)\n",
        "        self.enc_2 = EncoderNoSkip(128, 256)\n",
        "        self.enc_3 = EncoderNoSkip(256, 512)\n",
        "        self.enc_4 = EncoderNoSkip(512, 1024)\n",
        "\n",
        "        self.dec_1 = DecoderNoSkip(1024, 512)\n",
        "        self.dec_2 = DecoderNoSkip(512, 256)\n",
        "        self.dec_3 = DecoderNoSkip(256, 128)\n",
        "        self.dec_4 = DecoderNoSkip(128, 64)\n",
        "\n",
        "        self.out_conv = FinalOutputNoSkip(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resize_fnc(x)\n",
        "        x = self.in_conv1(x)\n",
        "        x = self.in_conv2(x)\n",
        "\n",
        "        x = self.enc_1(x)\n",
        "        x = self.enc_2(x)\n",
        "        x = self.enc_3(x)\n",
        "        x = self.enc_4(x)\n",
        "\n",
        "        x = self.dec_1(x)\n",
        "        x = self.dec_2(x)\n",
        "        x = self.dec_3(x)\n",
        "        x = self.dec_4(x)\n",
        "\n",
        "        x = self.out_conv(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zlVkb0M3ibVm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Inpainting with UNET"
      ],
      "metadata": {
        "id": "1HYU9MejjiW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, is_train=True):\n",
        "        self.resize = transforms.Resize((LOW_IMG_WIDTH, LOW_IMG_HEIGHT), antialias=True)\n",
        "        self.is_train = is_train\n",
        "        self.img_dir = img_dir\n",
        "        self.images = os.listdir(img_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def normalize(self, input_image, target_image):\n",
        "        input_image = input_image * 2 - 1\n",
        "        target_image = target_image * 2 - 1\n",
        "        return input_image, target_image\n",
        "\n",
        "    def random_jitter(self, input_image, target_image):\n",
        "        if torch.rand([]) < 0.5:\n",
        "            input_image = transforms.functional.hflip(input_image)\n",
        "            target_image = transforms.functional.hflip(target_image)\n",
        "        return input_image, target_image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        image = transforms.functional.to_tensor(image)\n",
        "\n",
        "        input_image = self.resize(image).type(torch.float32)\n",
        "        target_image = image.type(torch.float32)\n",
        "\n",
        "        input_image, target_image = self.normalize(input_image, target_image)\n",
        "\n",
        "        if self.is_train:\n",
        "            input_image, target_image = self.random_jitter(input_image, target_image)\n",
        "\n",
        "        return input_image, target_image"
      ],
      "metadata": {
        "id": "aB352-jCic7T"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "LOW_IMG_WIDTH = 64\n",
        "LOW_IMG_HEIGHT = 64\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, is_train=True):\n",
        "        self.is_train = is_train\n",
        "        self.img_dir = img_dir\n",
        "        self.images = os.listdir(img_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def normalize(self, input_image, target_image):\n",
        "        input_image = input_image * 2 - 1\n",
        "        target_image = target_image * 2 - 1\n",
        "        return input_image, target_image\n",
        "\n",
        "    def random_jitter(self, input_image, target_image):\n",
        "        if torch.rand([]) < 0.5:\n",
        "            input_image = transforms.functional.hflip(input_image)\n",
        "            target_image = transforms.functional.hflip(target_image)\n",
        "        return input_image, target_image\n",
        "\n",
        "    def create_mask(self, image):\n",
        "        masked_image = image.copy()\n",
        "        mask = np.full((IMG_WIDTH, IMG_HEIGHT, 3), 0, np.uint8)\n",
        "        for _ in range(np.random.randint(1, 5)):\n",
        "            x1, x2 = np.random.randint(1, IMG_WIDTH), np.random.randint(1, IMG_WIDTH)\n",
        "            y1, y2 = np.random.randint(1, IMG_HEIGHT), np.random.randint(1, IMG_HEIGHT)\n",
        "            thickness = np.random.randint(1, 15)\n",
        "            cv2.line(mask, (x1, y1), (x2, y2), (1, 1, 1), thickness)\n",
        "\n",
        "        masked_image = np.where(mask, 255 * np.ones_like(mask), masked_image)\n",
        "        return masked_image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "\n",
        "        input_image = self.create_mask(image)\n",
        "        input_image = transforms.functional.to_tensor(input_image)\n",
        "        target_image = transforms.functional.to_tensor(image)\n",
        "\n",
        "        input_image = input_image.type(torch.float32)\n",
        "        target_image = target_image.type(torch.float32)\n",
        "\n",
        "        input_image, target_image = self.normalize(input_image, target_image)\n",
        "\n",
        "        if self.is_train:\n",
        "            input_image, target_image = self.random_jitter(input_image, target_image)\n",
        "\n",
        "        return input_image, target_image"
      ],
      "metadata": {
        "id": "CIPw3Q_YjSVY"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}